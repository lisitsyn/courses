{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.optimize as opt\n",
    "import scipy.linalg as linalg\n",
    "import sklearn.linear_model\n",
    "import sklearn.model_selection\n",
    "import pandas as pd\n",
    "from sklearn.datasets.samples_generator import make_blobs, make_moons\n",
    "from sklearn.datasets import load_iris\n",
    "from IPython.display import Markdown as md\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Applied Machine Learning\n",
    "\n",
    "## Metrics: regression and classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Metrics and loss\n",
    "\n",
    "- Metric is how do we measure how good our model is\n",
    "- Loss function is what model optimizes for\n",
    "- They are not always the same (or even always not the same)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example\n",
    "\n",
    "- In classification we might be interested in accuracy\n",
    "- We can't optimize for accuracy (it's an NP problem)\n",
    "- That's why we used surrogate losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Baseline\n",
    "\n",
    "- No matter what metric we use, we're always interested in the best (simplest) solution \n",
    "- We can relate our solution to the baseline to understand thing better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Metric design\n",
    "\n",
    "- We will consider a few metrics next\n",
    "- You can always design your own metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Regression metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Mean Squared Error (MSE)\n",
    "\n",
    "$\\textsf{MSE}(y, \\hat y) = \\frac{1}{N} \\sum_{i=1}^{N} (y_i - \\hat y_i)^2$\n",
    "\n",
    "- Usually optimized directly, loss = metric\n",
    "- Punishes large outliers\n",
    "- What is the baseline (best constant)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Root MSE (RMSE)\n",
    "\n",
    "$\\textsf{RMSE}(y, \\hat y) = \\sqrt{\\frac{1}{N} \\sum_{i=1}^{N} (y_i - \\hat y_i)^2}$\n",
    "\n",
    "- Metric, not a loss optimized directly\n",
    "- Trivial that MSE minimum is also RMSE minimum\n",
    "- Absolute values make more sense than MSEs: prediction is 3, RMSE = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Mean Absolute Error (MAE)\n",
    "\n",
    "$\\textsf{MAE}(y, \\hat y) = \\frac{1}{N} \\sum_{i=1}^{N} \\left| y_i - \\hat y_i \\right| $\n",
    "\n",
    "- Non differentiable but can be optimized directly\n",
    "- Absolute values make some sense\n",
    "- Tolerate outliers, thus more robust\n",
    "- In MSE average is a minimizer, here it is median\n",
    "- [1, 4, 8, 10], min |x-1| + |x-4| + |x-8| + |x-10|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### $R^2$ aka coefficient of determination\n",
    "\n",
    "- It is a good idea to compare our performance to baseline\n",
    "- Given $\\overline y$ as the mean $y$, $R^2$ is defined as\n",
    "$$\n",
    "R^2 = 1 - \\frac{\\textit{residual sum} = MSE(y, \\hat y)}{\\textit{explained sum} = MSE(\\overline y, \\hat y)}\n",
    "$$\n",
    "- Basically tells the correlation between ground truth and predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Some errors are different\n",
    "\n",
    "- Is the \\\\$100 vs \\\\$101 the same as \\\\$1000 vs \\\\$1001 in predicting prices?\n",
    "- We need to respect this property in the metric\n",
    "- That's the case when the target column has long tails (e.g. exponential)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Mean Absolute Percentage Error (MAPE)\n",
    "\n",
    "$\\textsf{MAPE}(y, \\hat y) = \\frac{1}{N} \\sum_{i=1}^{N} \\left|\\frac{ y_i - \\hat y_i}{y_i}\\right| $\n",
    "\n",
    "- The values are interpretable and easy to report to someone else\n",
    "- MAE minimizer is also MAPE minimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### RMSE in log space\n",
    "\n",
    "- It is a common practice to logarithm skewed features\n",
    "- We can do the same thing to the target column\n",
    "- Measuring RMSE in this log-space is a good metric that solves the problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Classification metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Accuracy\n",
    "\n",
    "- The metric you can measure but not optimize\n",
    "- Even smallest imbalance makes it too optimistic\n",
    "- What happens if we predict if someone is sick with Ebola?\n",
    "- The accuracy for \"always healthy\" algorithm: 99.999999999%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Log loss\n",
    "\n",
    "Given $M$ classes and $N$ examples:\n",
    "$$\\textsf{log loss} = - \\frac{1}{N} \\sum_{i=1}^{N} \\sum_{j=1}^{M} y_{ij} \\log \\hat y_{ij},$$\n",
    "$y_{ij}$ is an indicator that $i$th examples is of $j$th class, $\\hat y_{ij}$ is the predicted probability of $i$th example being of $j$th class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Log loss\n",
    "\n",
    "- The loss function that is directly optimized\n",
    "- The baseline is the probability distribution over classes in target\n",
    "- In case of multiclass also known as cross-entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Confusion matrix\n",
    "\n",
    "$C, C_{ij} = \\textsf{the number of i-th class predicted as j-th class}$\n",
    "\n",
    "- Ideally, the confusion matrix is diagonal\n",
    "- Plotting the matrix as an image makes some sense sometimes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Confusion matrix for binary\n",
    "\n",
    "- We should declare one class as Positive, and one class as Negative\n",
    "- $C = \\left[\n",
    " \\begin{matrix}\n",
    "  TP & FP \\\\\n",
    "  FN & TN\n",
    " \\end{matrix}\n",
    "\\right]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[48,  5],\n",
       "       [ 4, 86]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_breast_cancer()\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.data, data.target, stratify=data.target, random_state=0)\n",
    "lr = LogisticRegression().fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Precision\n",
    "\n",
    "$\\textsf{precision} = \\frac{TP}{TP + FP}$\n",
    "\n",
    "- The ratio of Positives that are True Positives\n",
    "- Quite easy to get perfect precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Recall\n",
    "\n",
    "$\\textsf{recall} = \\frac{TP}{TP+FN}$\n",
    "\n",
    "- The ratio of True Positives among Positives \n",
    "- Quite easy to get perfect recall, but precision gets bad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Combining ratios: $F_1$\n",
    "\n",
    "- If you want to combine two values average is the usual thing\n",
    "- Actually, to combine two ratios it is wise to use harmonic average called $F_1$\n",
    "$F_1 = \\frac{2pr}{p+r}$\n",
    "- Precision=0.1, Recall=0.9, what are the averages: arithmetic and harmonic?\n",
    "- Arithmetic: (0.1 + 0.9)/2 = 0.5\n",
    "- Harmonic: (2 * 0.1 * 0.9) / (0.1 + 0.9) = 0.18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Thresholds\n",
    "\n",
    "- Most of the classifiers can actually predict some soft score\n",
    "- In binary classification, we choose some threshold $t$, $\\hat y > t$ leads to positive, otherwise negative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Receiver Operator Characteristics (ROC) curve\n",
    "\n",
    "- Plot for all thresholds points (FPR, TPR)\n",
    "- FPR is the rate of false positives over all positives (sensitivity)\n",
    "- TPR is the rate of true positives over all positives (specificity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Area Under Curve\n",
    "\n",
    "- It would be convenient to compare different ROC curves\n",
    "- The probability of ordering being correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Going multiclass\n",
    "\n",
    "- We can measure the same things per class\n",
    "- One can measure mean Precision, mean Recall, ...\n",
    "- Other ways include things like Cohen's Kappa"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
